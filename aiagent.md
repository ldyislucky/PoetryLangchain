# 1ã€å¤§ä½“æ¶æ„æ–¹æ¡ˆ

| ç±»åˆ«         | æŠ€æœ¯æ–¹æ¡ˆ             | è¯´æ˜                                                         |
| ------------ | -------------------- | ------------------------------------------------------------ |
| åŸºç¡€æ¨¡å‹     | DeepSeek-API         | é‡‡ç”¨å®˜æ–¹APIè¿›è¡Œæ¨¡å‹è°ƒç”¨ï¼Œæ”¯æŒæ–‡æœ¬ç”Ÿæˆã€æ„å›¾è¯†åˆ«ã€ä»£ç ç”Ÿæˆç­‰åœºæ™¯ |
| äº‘å¹³å°       | é˜¿é‡Œäº‘/è…¾è®¯äº‘        | é€‰æ‹©å®¹å™¨æœåŠ¡+Serverlessç»„åˆï¼ŒæŒ‰éœ€å¼¹æ€§ä¼¸ç¼©                    |
| å¼€å‘æ¡†æ¶     | FastAPI + LangChain  | å¿«é€Ÿæ„å»ºAgenté€»è¾‘ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨é“¾                            |
| éƒ¨ç½²æ¶æ„     | Kubernetes + Docker  | å®¹å™¨åŒ–éƒ¨ç½²ä¿éšœç¯å¢ƒä¸€è‡´æ€§                                     |
| æ•°æ®å­˜å‚¨     | Redis + mysql + OSS  | åˆ†çº§å­˜å‚¨ï¼šç¼“å­˜/ç»“æ„åŒ–æ•°æ®/æ–‡ä»¶å­˜å‚¨                           |
| æ¶ˆæ¯é˜Ÿåˆ—     | RocketMQ             | å¼‚æ­¥å¤„ç†é«˜å¹¶å‘è¯·æ±‚                                           |
| ç›‘æ§ä½“ç³»     | Prometheus + Grafana | å®æ—¶ç›‘æ§APIè°ƒç”¨ã€èµ„æºä½¿ç”¨æƒ…å†µï¼ˆå­¦ä¹ ä½¿ç”¨langsmithä»£æ›¿ï¼‰è¯­ä¹‰   |
| è¯­ä¹‰ç†è§£æ¨¡å‹ | huggingface          | ä½¿ç”¨ä¸­æ–‡ bge-large-zh-v1.5 æ¨¡å‹                              |

```mermaid
graph TD
    A["å®¢æˆ·ç«¯(Web/APP)"] --> B["API Gateway\n(èº«ä»½éªŒè¯/é™æµ)"]
    B --> C["åŒæ­¥è¯·æ±‚å¤„ç†\n(FastAPI)"]
    B --> D["å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—\n(RocketMQ)"]
    C --> E["ç¬¬ä¸‰æ–¹æœåŠ¡\n(æ”¯ä»˜/åœ°å›¾ç­‰)"]
    C --> F["Agentæ ¸å¿ƒ\n(LangChain)"]
    D --> G["ä»»åŠ¡å¤„ç†å™¨\n(Celery)"]
    F --> G
    G --> H["æ•°æ®åº“é›†ç¾¤\n(mysql+Redis)"]
    F --> I["DeepSeek API\n(æ¨¡å‹æœåŠ¡)"]
    E -.-> C
```

# 2ã€å¸¸ç”¨åŸºç¡€åŒ…æ¨è

  | åŒ…å           | ç”¨é€”                           |
  | :------------- | :----------------------------- |
  | numpy          | æ•°å€¼è®¡ç®—ï¼ˆå¤šç»´æ•°ç»„ã€çŸ©é˜µè¿ç®—ï¼‰ |
  | pandas         | æ•°æ®æ¸…æ´—ã€åˆ†æï¼ˆç±»ä¼¼Excelï¼‰    |
  | requests       | å‘é€HTTPè¯·æ±‚ï¼ˆè®¿é—®API/ç½‘é¡µï¼‰   |
  | matplotlib     | æ•°æ®å¯è§†åŒ–ï¼ˆç»˜åˆ¶å›¾è¡¨ï¼‰         |
  | jupyter        | äº¤äº’å¼ç¼–ç¨‹ç¯å¢ƒï¼ˆä»£ç +æ–‡æ¡£ï¼‰    |
  | scikit-learn   | æœºå™¨å­¦ä¹ ç®—æ³•åº“                 |
  | beautifulsoup4 | ç½‘é¡µè§£æï¼ˆçˆ¬è™«ï¼‰               |
  | flask          | è½»é‡çº§Webæ¡†æ¶                  |

# 3ã€pythonå¸¸ç”¨æŒ‡ä»¤

```text
æ¸…ç©ºæ‰€æœ‰ä¾èµ–ï¼Œ2ä¸ªè¯­å¥éƒ½æ‰§è¡Œï¼š
pip freeze > requirements.txt
pip uninstall -r requirements.txt -y
```

# 4ã€langchain

## 4.1ã€langserveé…ç½®

è¿™ä¸ªæ“ä½œæµç¨‹å­˜åœ¨æ··åˆä½¿ç”¨pipå’ŒPoetryå¯¼è‡´ä¾èµ–ç®¡ç†æ··ä¹±çš„é—®é¢˜ï¼Œçº æ­£åçš„å…¨Poetryæ“ä½œæµç¨‹å¦‚ä¸‹ï¼š

1. å®‰è£…å…¨å±€å·¥å…·ï¼ˆåœ¨ä»»æ„ç›®å½•æ‰§è¡Œï¼‰
```bash
# å®‰è£… pipxï¼ˆPythonå·¥å…·éš”ç¦»ç®¡ç†ï¼‰
python -m pip install --user pipx
python -m pipx ensurepath

# é€šè¿‡ pipx å®‰è£… poetry
pipx install poetry

pip install -U langchain-cli  #æ˜¯ LangChain çš„å‘½ä»¤è¡Œå·¥å…·
```

2. åˆ›å»ºé¡¹ç›®ï¼ˆåœ¨é¡¹ç›®ç›®å½•å¤–æ‰§è¡Œï¼‰
```bash
# å¦‚æœä½¿ç”¨poetry new langchainæ–°å»ºé¡¹ç›®ï¼Œåè¾¹å¯èƒ½è¿˜éœ€è¦æ‰§è¡Œç¬¬4æ­¥
langchain app new langchain
cd langchain

è§£å†³å†²çªçš„åŠæ³•æ˜¯å»æ‰pyproject.tomlä¸­çš„pydantic = "<2"

# åˆå§‹åŒ–é…ç½®ï¼ˆæ ¹æ®éœ€è¦è°ƒæ•´pyproject.tomlï¼‰
```

3. ç»Ÿä¸€ç”¨Poetryç®¡ç†ä¾èµ–ï¼ˆåœ¨é¡¹ç›®ç›®å½•æ‰§è¡Œï¼‰
```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–ï¼ˆæ›¿ä»£åŸpipå®‰è£…æ­¥éª¤ï¼‰
poetry add "langserve[all]"   #è¶…æ—¶é—®é¢˜å¯ä»¥å•ç‹¬å®‰è£…æŸä¸ªä¾èµ–ï¼Œeg: poetry add anyio
poetry add langchain-deepseek
poetry add langchain-community

# å¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–ä¾èµ–
poetry add langchain
```

4. é¡¹ç›®é…ç½®å’Œä»£ç ä¿®æ”¹
```bash
# åˆ›å»ºæœåŠ¡æ–‡ä»¶ï¼ˆæ‰‹åŠ¨åˆ›å»ºapp/server.pyï¼‰
# æŒ‰åŸéœ€æ±‚ä¿®æ”¹server.pyå†…å®¹
```

5. è¿è¡ŒæœåŠ¡ï¼ˆåœ¨é¡¹ç›®ç›®å½•æ‰§è¡Œï¼‰
```bash
# åœ¨ poetry è™šæ‹Ÿç¯å¢ƒä¸­å¯åŠ¨æœåŠ¡
poetry run langchain serve
```

## 4.2ã€å…¶å®ƒé…ç½®

***poetryé•œåƒé…ç½®åŠä½¿ç”¨***

```markdown
# é•œåƒæºé…ç½®ï¼Œåœ¨pyproject.tomlä¸­æ·»åŠ :
[[tool.poetry.source]]
name = "tuna"
url = "https://pypi.tuna.tsinghua.edu.cn/simple"

# é•œåƒæºä½¿ç”¨ï¼š
poetry add numpy --source tuna
```

***ç›‘æ§é…ç½®***

```powershell
#é…ç½®LangSmith ç›‘æ§å¼€å…³ï¼Œtrueå¼€å¯ï¼Œfalseå…³é—­
SetX LANGCHAIN_TRACING_V2 "true"

#é…ç½® LangSmith api key
SetX LANGCHAIN_API_KEY "your_api_key_here"  # ç”¨æˆ·çº§å˜é‡

```

LangSmithå®˜ç½‘:https://smith.langchain.com/ 

***æœç´¢é…ç½®***

```powershell
#é…ç½® taily api key
SetX TAVILY_API_KEY "..."
```

tavilyå®˜ç½‘:https://tavily.com/

# 5ã€embeddings-è¯­ä¹‰ç†è§£

å°†è¯­ä¹‰ç†è§£æ¨¡å‹ä¸‹è½½è‡³æœ¬åœ°ï¼ˆä»¥bge-small-zh-v1.5ä¸ºä¾‹ï¼‰

```markdown
# åˆå§‹åŒ– Git LFS æ”¯æŒå¹¶é…ç½® Git ä»“åº“ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†å¤§æ–‡ä»¶ã€‚
git lfs install
     
# å…‹éš†bge-small-zh-v1.5æ¨¡å‹åˆ°æœ¬åœ°
git clone https://huggingface.co/BAAI/bge-small-zh-v1.5
```

pythonä»£ç ä½¿ç”¨FlagEmbeddingè¯´æ˜ä¸¾ä¾‹

```python
from FlagEmbedding import FlagModel

# åˆå§‹åŒ–FlagModelæ¨¡å‹
# å‚æ•°è¯´æ˜ï¼š
# - model_path: æ¨¡å‹è·¯å¾„ï¼ŒæŒ‡å‘é¢„è®­ç»ƒæ¨¡å‹çš„å­˜å‚¨ä½ç½®
# - query_instruction_for_retrieval: ä¸ºæ£€ç´¢ä»»åŠ¡æ·»åŠ çš„æŒ‡ä»¤ï¼Œç”¨äºç”ŸæˆæŸ¥è¯¢çš„è¡¨ç¤º
# - use_fp16: æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°ï¼ˆFP16ï¼‰åŠ é€Ÿè®¡ç®—ï¼Œå¯èƒ½ä¼šç•¥å¾®é™ä½æ€§èƒ½
model = FlagModel('D:/D/document/donotdelete/models/bge-small-zh/bge-small-zh-v1.5',
                  query_instruction_for_retrieval="ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š",
                  use_fp16=True)

# å®šä¹‰ä¸¤ä¸ªå¥å­åˆ—è¡¨ï¼Œç”¨äºç”ŸæˆåµŒå…¥å‘é‡
sentences_1 = ["æ ·ä¾‹æ•°æ®-1", "æ ·ä¾‹æ•°æ®-2"]
sentences_2 = ["æ ·ä¾‹æ•°æ®-3", "æ ·ä¾‹æ•°æ®-4"]

# ä½¿ç”¨æ¨¡å‹å¯¹å¥å­åˆ—è¡¨è¿›è¡Œç¼–ç ï¼Œç”Ÿæˆå¯¹åº”çš„åµŒå…¥å‘é‡
embeddings_1 = model.encode(sentences_1)
embeddings_2 = model.encode(sentences_2)

# è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡é›†åˆçš„ç›¸ä¼¼åº¦çŸ©é˜µ
similarity = embeddings_1 @ embeddings_2.T
print(similarity)

print("\n===============================\n")

# å¯¹äºçŸ­æŸ¥è¯¢åˆ°é•¿æ–‡æ¡£ï¼ˆs2pï¼‰çš„æ£€ç´¢ä»»åŠ¡ï¼Œå»ºè®®ä½¿ç”¨encode_queries()æ–¹æ³•
# è¯¥æ–¹æ³•ä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ªæŸ¥è¯¢æ·»åŠ æŒ‡ä»¤ï¼Œé€‚åˆå¤„ç†çŸ­æŸ¥è¯¢
# è€Œæ–‡æ¡£é›†åˆå¯ä»¥ç»§ç»­ä½¿ç”¨encode()æˆ–encode_corpus()æ–¹æ³•ï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦é¢å¤–æŒ‡ä»¤
queries = ['query_1', 'query_2']
passages = ["æ ·ä¾‹æ–‡æ¡£-1", "æ ·ä¾‹æ–‡æ¡£-2"]

# å¯¹æŸ¥è¯¢å’Œæ–‡æ¡£åˆ†åˆ«ç”ŸæˆåµŒå…¥å‘é‡
q_embeddings = model.encode_queries(queries)
p_embeddings = model.encode(passages)

# è®¡ç®—æŸ¥è¯¢ä¸æ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼åº¦å¾—åˆ†çŸ©é˜µ
scores = q_embeddings @ p_embeddings.T
print(scores)

```

pythonä»£ç ä½¿ç”¨sentence_transformersè¯´æ˜ä¸¾ä¾‹

```python
from sentence_transformers import SentenceTransformer

# å®šä¹‰æŸ¥è¯¢å’Œæ–‡æ¡£é›†åˆ
queries = ['query_1', 'query_2']  # æŸ¥è¯¢åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºä¸€ä¸ªæŸ¥è¯¢å­—ç¬¦ä¸²
passages = ["æ ·ä¾‹æ–‡æ¡£-1", "æ ·ä¾‹æ–‡æ¡£-2"]  # æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºä¸€ä¸ªæ–‡æ¡£å­—ç¬¦ä¸²
instruction = "ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š"  # æŒ‡ä»¤å­—ç¬¦ä¸²ï¼Œç”¨äºå¢å¼ºæŸ¥è¯¢çš„è¯­ä¹‰ä¿¡æ¯

# åŠ è½½æœ¬åœ°é¢„è®­ç»ƒæ¨¡å‹
model_path = "D:/D/document/donotdelete/models/bge-small-zh/bge-small-zh-v1.5"  
# æ¨¡å‹è·¯å¾„ï¼šæŒ‡å‘æœ¬åœ°å­˜å‚¨çš„SentenceTransformeræ¨¡å‹æ–‡ä»¶å¤¹ï¼Œéœ€åŒ…å«pytorch_model.binç­‰å¿…è¦æ–‡ä»¶
model = SentenceTransformer(model_path)

# å¯¹æŸ¥è¯¢è¿›è¡Œç¼–ç ï¼Œç”ŸæˆæŸ¥è¯¢åµŒå…¥å‘é‡
# å°†æŒ‡ä»¤ä¸æ¯ä¸ªæŸ¥è¯¢æ‹¼æ¥åç¼–ç ï¼Œå¹¶å¯¹åµŒå…¥å‘é‡è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
q_embeddings = model.encode([instruction + q for q in queries], normalize_embeddings=True)

# å¯¹æ–‡æ¡£é›†åˆè¿›è¡Œç¼–ç ï¼Œç”Ÿæˆæ–‡æ¡£åµŒå…¥å‘é‡
# å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡Œç¼–ç ï¼Œå¹¶å¯¹åµŒå…¥å‘é‡è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
p_embeddings = model.encode(passages, normalize_embeddings=True)

# è®¡ç®—æŸ¥è¯¢ä¸æ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°
# ä½¿ç”¨çŸ©é˜µä¹˜æ³•è®¡ç®—æŸ¥è¯¢åµŒå…¥ä¸æ–‡æ¡£åµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦
scores = q_embeddings @ p_embeddings.T

# è¾“å‡ºæ¯ä¸ªæŸ¥è¯¢ä¸æ–‡æ¡£çš„ç›¸ä¼¼åº¦åˆ†æ•°
for query, score in zip(queries, scores):
    print(f"query: {query}")  # æ‰“å°å½“å‰æŸ¥è¯¢
    for passage, score in zip(passages, score):
        # æ‰“å°æ¯ä¸ªæ–‡æ¡£åŠå…¶ä¸å½“å‰æŸ¥è¯¢çš„ç›¸ä¼¼åº¦åˆ†æ•°
        print(f"passage: {passage}, score: {score}")
```

pythonä»£ç ä½¿ç”¨Langchainè¯´æ˜ä¸¾ä¾‹

```python
from langchain_huggingface import HuggingFaceEmbeddings

# åˆå§‹åŒ– HuggingFaceBgeEmbeddings æ¨¡å‹çš„é…ç½®å’Œå®ä¾‹åŒ–
# å‚æ•°è¯´æ˜ï¼š
# - model_name: æŒ‡å®šä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è·¯å¾„ï¼Œä¾‹å¦‚ "BAAI/bge-large-en-v1.5"ã€‚
# - model_kwargs: æ¨¡å‹åŠ è½½æ—¶çš„é¢å¤–å‚æ•°ï¼Œä¾‹å¦‚æŒ‡å®šè®¾å¤‡ä¸º 'cuda' ä»¥ä½¿ç”¨ GPU åŠ é€Ÿã€‚
# - encode_kwargs: ç¼–ç æ—¶çš„é¢å¤–å‚æ•°ï¼Œä¾‹å¦‚è®¾ç½® 'normalize_embeddings' ä¸º True ä»¥è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ã€‚
# - query_instruction: æŸ¥è¯¢æŒ‡ä»¤ï¼Œç”¨äºç”Ÿæˆå¥å­è¡¨ç¤ºä»¥æ”¯æŒæ£€ç´¢ä»»åŠ¡ã€‚
# è¿”å›å€¼ï¼šæ— ï¼ˆä»£ç ç‰‡æ®µæœªåŒ…å«è¿”å›å€¼é€»è¾‘ï¼‰

model_name = "D:/D/document/donotdelete/models/bge-small-zh/bge-small-zh-v1.5"  # æŒ‡å®šä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹åç§°

# é…ç½®æ¨¡å‹åŠ è½½å‚æ•°ï¼ŒæŒ‡å®šè®¾å¤‡ä¸º GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œåˆ™éœ€ä¿®æ”¹ä¸º 'cuda'
model_kwargs = {'device': 'cpu'}

# é…ç½®ç¼–ç å‚æ•°ï¼Œè®¾ç½® normalize_embeddings ä¸º True ä»¥æ”¯æŒä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
encode_kwargs = {'normalize_embeddings': True}

# å®ä¾‹åŒ– HuggingFaceBgeEmbeddings æ¨¡å‹ï¼Œä¼ å…¥æ¨¡å‹åç§°ã€åŠ è½½å‚æ•°ã€ç¼–ç å‚æ•°å’ŒæŸ¥è¯¢æŒ‡ä»¤
model = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs,
)

def generate_query_embedding(query: str):
    # æ‰‹åŠ¨æ‹¼æ¥æŸ¥è¯¢æŒ‡ä»¤
    full_query = f"ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š{query}"
    return model.embed_query(full_query)

# ç¤ºä¾‹è°ƒç”¨
query = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬"
embedding = generate_query_embedding(query)
print(embedding)

```

# 6ã€RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰+langchat

## RAGå®Œæ•´æµç¨‹ï¼š

```markdown
ç”¨æˆ·è¾“å…¥ â†’ retrieval_chain.invoke() â†’ åˆå¹¶å†å²(create_history_aware_retrieve) â†’ create_history_aware_retrieveé‡å†™åçš„é—®é¢˜ä½œç”¨äºæ£€ç´¢å™¨ï¼ˆä¸åšç”¨äºæ–‡æ¡£å¤„ç†é“¾ï¼‰ â†’ æ£€ç´¢æ–‡æ¡£(retriever) â†’ å°†æ£€ç´¢ç»“æœå‘é€ç»™create_stuff_documents_chai â†’  create_stuff_documents_chaiæ ¹æ®åŸå§‹é—®é¢˜å’Œæ£€ç´¢ç»“æœã€å†å²èŠå¤©è®°å½•ç”Ÿæˆæœ€ç»ˆå›ç­” â†’ æ›´æ–°å†å²èŠå¤©è®°å½•ã€‚

# æµç¨‹æ­¥éª¤ï¼ˆæ³¨é‡Šæˆ–æ–‡æ¡£ä¸­ï¼‰
1. ğŸ“¥ ç”¨æˆ·è¾“å…¥ 
   - è¾“å…¥: {"input": "é—®é¢˜", "chat_history": [...]}
   - æ“ä½œ: è§¦å‘ retrieval_chain.invoke()

2. ğŸ”„ åˆå¹¶å†å² (create_history_aware_retriever)
   - è¾“å…¥: åŸå§‹é—®é¢˜ + å†å²å¯¹è¯
   - æ“ä½œ: é‡å†™é—®é¢˜ â†’ "ä¼˜åŒ–åçš„é—®é¢˜"
   - è¾“å‡º: {"optimized_query": "ä¼˜åŒ–åçš„é—®é¢˜"}

3. ğŸ” æ£€ç´¢æ–‡æ¡£ (retriever)
   - è¾“å…¥: ä¼˜åŒ–åçš„é—®é¢˜
   - æ“ä½œ: ä»æ•°æ®åº“/å‘é‡åº“æ£€ç´¢
   - è¾“å‡º: [Document1, Document2...]

4. ğŸ› ï¸ ç”Ÿæˆå›ç­” (create_stuff_documents_chain)
   - è¾“å…¥: ç”¨æˆ·çš„åŸå§‹é—®é¢˜ + æ£€ç´¢åˆ°çš„æ–‡æ¡£ + å†å²èŠå¤©è®°å½•
   - æ“ä½œ: æ¨¡å‹ç”Ÿæˆå›ç­”
   - è¾“å‡º: {"answer": "æœ€ç»ˆå›ç­”"}

5. ğŸ“ æ›´æ–°å†å²
   - è¾“å…¥: åŸå§‹é—®é¢˜ + æœ€ç»ˆå›ç­”
   - æ“ä½œ: è¿½åŠ åˆ° chat_history
   - è¾“å‡º: æ›´æ–°åçš„ {"chat_history": [...]}

```

åœ¨LangChainæ¡†æ¶ä¸­ï¼Œcreate_stuff_documents_chainã€create_history_aware_retrieverå’Œcreate_retrieval_chainæ˜¯æ„å»ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æµç¨‹çš„æ ¸å¿ƒç»„ä»¶ã€‚å®ƒä»¬å„è‡ªæ‰¿æ‹…ä¸åŒçš„è§’è‰²ï¼Œåä½œå®ç°ç»“åˆå†å²ä¸Šä¸‹æ–‡çš„é«˜æ•ˆæ–‡æ¡£æ£€ç´¢ä¸å›ç­”ç”Ÿæˆã€‚ä»¥ä¸‹æ˜¯å®ƒä»¬çš„ä½œç”¨å’ŒåŒºåˆ«ï¼š

## create_stuff_documents_chainâ€Œ

**ä½œç”¨â€Œï¼š**
åˆ›å»ºä¸€ä¸ªâ€Œæ–‡æ¡£å¤„ç†é“¾â€Œï¼Œè´Ÿè´£å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹æ•´åˆåè¾“å…¥è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”ã€‚å…¶æ ¸å¿ƒæ˜¯â€œStuffingâ€æ–¹æ³•ï¼Œå³ç›´æ¥å°†æ‰€æœ‰ç›¸å…³æ–‡æ¡£å†…å®¹æ‹¼æ¥ä¸ºå•ä¸ªä¸Šä¸‹æ–‡ï¼Œä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·ä¼ ç»™æ¨¡å‹ã€‚è¿™ç§æ–¹å¼ç®€å•é«˜æ•ˆï¼Œä½†éœ€æ³¨æ„æ¨¡å‹è¾“å…¥é•¿åº¦é™åˆ¶ã€‚

**é€‚ç”¨åœºæ™¯â€Œï¼š**
å½“æ–‡æ¡£æ•°é‡è¾ƒå°‘æˆ–å†…å®¹è¾ƒçŸ­æ—¶ï¼Œç›´æ¥å°†å…¨éƒ¨å†…å®¹å¡å…¥ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ¨¡å‹è·å–å®Œæ•´ä¿¡æ¯ã€‚

**ç¤ºä¾‹ä»£ç é€»è¾‘â€Œï¼š**

```python
#  è¾“å…¥ï¼šç”¨æˆ·é—®é¢˜ + æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨ â†’ è¾“å‡ºï¼šæ¨¡å‹ç”Ÿæˆçš„å›ç­”
chain = create_stuff_documents_chain(llm, prompt)
```

## create_history_aware_retrieverâ€Œ

**ä½œç”¨â€Œï¼š**
åˆ›å»ºä¸€ä¸ªâ€Œå†å²æ„ŸçŸ¥çš„æ£€ç´¢å™¨â€Œï¼Œåœ¨æ£€ç´¢æ–‡æ¡£æ—¶è€ƒè™‘å¯¹è¯å†å²ï¼Œä¼˜åŒ–å½“å‰æŸ¥è¯¢ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·åç»­é—®é¢˜å¯èƒ½ä¾èµ–ä¹‹å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œè¯¥ç»„ä»¶ä¼šåŠ¨æ€è°ƒæ•´æŸ¥è¯¢è¯­å¥ä»¥æé«˜æ£€ç´¢ç›¸å…³æ€§ã€‚

**æŠ€æœ¯ç»†èŠ‚â€Œï¼š**

ç»“åˆå†å²ä¿¡æ¯é‡æ–°ç”Ÿæˆæˆ–ä¼˜åŒ–æŸ¥è¯¢ï¼ˆå¦‚é€šè¿‡LLMé‡å†™é—®é¢˜ï¼‰ã€‚
ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢ä»å‘é‡åº“ç­‰æ•°æ®æºæ£€ç´¢æ–‡æ¡£ã€‚

**ç¤ºä¾‹ä»£ç é€»è¾‘â€Œï¼š**

```python
#  è¾“å…¥ï¼šç”¨æˆ·å½“å‰é—®é¢˜ + å¯¹è¯å†å² â†’ è¾“å‡ºï¼šä¼˜åŒ–æŸ¥è¯¢åçš„ç›¸å…³æ–‡æ¡£
retriever = create_history_aware_retriever(llm, base_retriever, prompt)
```

## create_retrieval_chainâ€Œ

**ä½œç”¨â€Œï¼š**
å°†â€Œå†å²æ„ŸçŸ¥æ£€ç´¢å™¨â€Œå’Œâ€Œæ–‡æ¡£å¤„ç†é“¾â€Œæ•´åˆä¸ºç«¯åˆ°ç«¯çš„æµç¨‹ï¼Œå½¢æˆå®Œæ•´çš„RAGé“¾ã€‚ç”¨æˆ·è¾“å…¥ä¾æ¬¡ç»è¿‡æ£€ç´¢å’Œç”Ÿæˆä¸¤é˜¶æ®µï¼Œè‡ªåŠ¨å¤„ç†å†å²ä¸Šä¸‹æ–‡ã€æ£€ç´¢æ–‡æ¡£åŠç”Ÿæˆå›ç­”ã€‚

**åä½œæµç¨‹â€Œï¼š**

æ£€ç´¢é˜¶æ®µâ€Œï¼šåˆ©ç”¨create_history_aware_retrieverç”Ÿæˆçš„æ£€ç´¢å™¨ï¼Œç»“åˆå†å²ä¼˜åŒ–æŸ¥è¯¢ï¼Œè·å–ç›¸å…³æ–‡æ¡£ã€‚
ç”Ÿæˆé˜¶æ®µâ€Œï¼šé€šè¿‡create_stuff_documents_chainç”Ÿæˆçš„é“¾ï¼Œå°†æ–‡æ¡£å’Œé—®é¢˜è¾“å…¥LLMç”Ÿæˆå›ç­”ã€‚

**ç¤ºä¾‹ä»£ç é€»è¾‘â€Œï¼š**

```python
#  è¾“å…¥ï¼šç”¨æˆ·å½“å‰é—®é¢˜ + å¯¹è¯å†å² â†’ è¾“å‡ºï¼šæœ€ç»ˆå›ç­”ï¼ˆè‡ªåŠ¨å¤„ç†æ£€ç´¢å’Œç”Ÿæˆï¼‰
retrieval_chain = create_retrieval_chain(retriever, document_chain)
```



